{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial examples for a DNN via Integer Linear Programming\n",
    "\n",
    "_Combinatorial Optimization course, FEE CTU in Prague. Created by [Industrial Informatics Department](http://industrialinformatics.fel.cvut.cz)._\n",
    "\n",
    "In this assigment you will learn that ILP can be used as a powerful tool for formal verification of complex systems. The application shown here concern of finding adverdarial examples that could fool a DNN trained with Tensorflow that perform handwritten digits recogtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_5615/3711040673.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mgurobipy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mscipy\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gurobipy as g\n",
    "import scipy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us download MNIST dataset - a favourite benchmark for handwritten digit recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how our the data look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2, 3)\n",
    "plt.gray()\n",
    "axarr[0, 0].imshow(x_train[0, :])\n",
    "axarr[0, 0].set_title('class:'+str(y_train[0]))\n",
    "axarr[0, 1].imshow(x_train[1, :])\n",
    "axarr[0, 1].set_title('class:'+str(y_train[1]))\n",
    "axarr[0, 2].imshow(x_train[2, :])\n",
    "axarr[0, 2].set_title('class:'+str(y_train[2]))\n",
    "axarr[1, 0].imshow(x_train[3, :])\n",
    "axarr[1, 0].set_title('class:'+str(y_train[3]))\n",
    "axarr[1, 1].imshow(x_train[4, :])\n",
    "axarr[1, 1].set_title('class:'+str(y_train[4]))\n",
    "axarr[1, 2].imshow(x_train[5, :])\n",
    "axarr[1, 2].set_title('class:'+str(y_train[5]))\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we build a very simple DNN using Keras API for Tensorflow. We will use four dense connected layers. _You may adjust sizes of the hidden layers for your experiments._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(48, activation='relu'),\n",
    "  tf.keras.layers.Dense(27, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This the ReLU activation function $f_{\\boldsymbol{w}, b}(\\boldsymbol{x}) = \\max \\{\\boldsymbol{w}^T\\boldsymbol{x} + b, 0\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 100)\n",
    "plt.plot(x, list(map(lambda t: max(t, 0), x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are using a dense fully connected network with ReLU activations. Next, we apply a standard loss function for multi-label classication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And next, we train the network. Notice that this is an optimization problem as well - optimizing the given loss function over the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=5)\n",
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how the training went:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see accuracy above 0.9, then the training went well and we likely did not overfit the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we would like to test wheter the trained model works and intended. Lets ask our model on few inputs as a sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = probability_model(x_test[0:4])\n",
    "f, axarr = plt.subplots(ncols=4)\n",
    "plt.gray()\n",
    "for k in range(4):\n",
    "    axarr[k].imshow(x_test[k, :])\n",
    "    axarr[k].set_title('true: {}, pred: {}'.format(y_test[k], max(range(10), key=lambda idx: preds[k][idx])))\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it comes to the interesting part. Is our DNN model foolproof? To find out that, we would like to have something like an \"inverse\" function to the network - which would map output to the input. However, this is not provided by the trained model.\n",
    "\n",
    "Interestingly, we will show that such inverse can be realized with an ILP model. First, we will construct an ILP model that can be used for inference task - mapping inputs to outputs using the trained weights. Later on, we will use it for as the inverse function of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets explore the structure of your weight matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weights)\n",
    "print(weights[0].shape)\n",
    "print(weights[1].shape)\n",
    "print(weights[2].shape)\n",
    "print(weights[3].shape)\n",
    "print(weights[4].shape)\n",
    "print(weights[5].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the structure contains always a matrix of weights coefficient and a vector of biases for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = [weights[0], weights[2], weights[4]]\n",
    "b = [weights[1], weights[3], weights[5]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ILP to perform the inference given the trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will construct an ILP model that is able to perform the inference in the network with the given trained weights $W$ and biases $b$.\n",
    "\n",
    "We use a variable $f_{k,i}$ that denotes the output of $i$-th neuron in layer $k$ and $y_{k, i}$ which denotes the input signal of the corresponding neuron. $x$ variables serve as the input of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilp_model = g.Model()\n",
    "x = ilp_model.addVars(W[0].shape[0], vtype=g.GRB.CONTINUOUS, lb=0, ub=1)\n",
    "f = {}\n",
    "y = {}\n",
    "for k in range(3):\n",
    "    for i in range(W[k].shape[0]):\n",
    "        f[k, i] = ilp_model.addVar(vtype=g.GRB.CONTINUOUS, lb=0)\n",
    "        y[k, i] = ilp_model.addVar(vtype=g.GRB.CONTINUOUS, lb=-float('inf'))\n",
    "for i in range(W[2].shape[1]):\n",
    "        f[3, i] = ilp_model.addVar(vtype=g.GRB.CONTINUOUS, lb=0)\n",
    "        y[3, i] = ilp_model.addVar(vtype=g.GRB.CONTINUOUS, lb=-float('inf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to establish proper constraints according to the structure of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(W[0].shape[0]):\n",
    "    ilp_model.addConstr(x[i] == f[0, i])\n",
    "for k in range(1,4):\n",
    "    for i in range(W[k-1].shape[1]):\n",
    "        ilp_model.addConstr(g.quicksum(W[k-1][j, i]*f[k-1, j] for j in range(W[k-1].shape[0])) + b[k-1][i] == y[k, i])\n",
    "        ilp_model.addConstr(f[k, i] == g.max_(y[k, i], 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us note a small remark. Here we have used $\\max$ in the constraints, which __is not a linear operation!__ We could linearize it and convert it back to a proper ILP model, but for sake of clarity let us keep like it is. Luckily, Gurobi can handle this one on its own. But please, do not use this construct in different solvers or your theoretical tests! This is not a feature of ILP but this particular solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference DNN / ILP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try the inference task using our ILP model. Consider, e.g., the following input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = 12\n",
    "plt.gray()\n",
    "plt.imshow(x_test[test_idx, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let us use the trained DNN to classify it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = probability_model(x_test[test_idx:test_idx+1])\n",
    "print('classified by the trained DNN as {} with probability p={}'.format(\n",
    "        max(range(10), key=lambda idx: prediction[0][idx]), max(prediction[0]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now lets do the same with our implementation of DNN as an ILP model. We \"feed\" the input to the network by imposing equality constaints on our $x_i$ variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input_flatten = x_test[test_idx, :].reshape(1, 28*28)\n",
    "for i in range(W[0].shape[0]):\n",
    "    ilp_model.addConstr(x[i] == x_input_flatten[0][i])\n",
    "    \n",
    "ilp_model.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the activations of the output layer and, as a sanity check, the softmax over the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [f[3, i].x for i in range(10)]\n",
    "probs = np.exp(result)/sum(np.exp(result))\n",
    "print('activations: ', result)\n",
    "print('probabilities: ', probs)\n",
    "pred_class_by_dnn = max(range(10), key=lambda idx: result[idx])\n",
    "print('classified by ILP as {} with probability p={}'.format(\n",
    "        pred_class_by_dnn, max(prediction[0]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fooling the network - find a small perturbation of the input data by ILP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems to work as intended. Now is the time to use ILP model as an inverse function of the model. We try to fool the network and find a small deviation of the input that will make the network to do a mistake. \n",
    "\n",
    "Let us find the smallest deviaton of a sample from the test set, that will cause the network to give incorrect classification on that sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilp_model = g.Model()\n",
    "x = ilp_model.addVars(W[0].shape[0], vtype=g.GRB.CONTINUOUS, lb=0, ub=1)\n",
    "delta = ilp_model.addVars(W[0].shape[0], vtype=g.GRB.CONTINUOUS, lb=-1, ub=1)  # our vector of deviations\n",
    "input_diff = ilp_model.addVars(W[0].shape[0], vtype=g.GRB.CONTINUOUS, lb=-1, ub=1)   \n",
    "max_activation = ilp_model.addVar(vtype=g.GRB.CONTINUOUS, lb=0)\n",
    "f = {}\n",
    "y = {}\n",
    "for k in range(3):\n",
    "    for i in range(W[k].shape[0]):\n",
    "        f[k, i] = ilp_model.addVar(vtype=g.GRB.CONTINUOUS, lb=0)\n",
    "        y[k, i] = ilp_model.addVar(vtype=g.GRB.CONTINUOUS, lb=-float('inf'))\n",
    "for i in range(W[2].shape[1]):\n",
    "        f[3, i] = ilp_model.addVar(vtype=g.GRB.CONTINUOUS, lb=0)\n",
    "        y[3, i] = ilp_model.addVar(vtype=g.GRB.CONTINUOUS, lb=-float('inf'))\n",
    "for i in range(W[0].shape[0]):\n",
    "    ilp_model.addConstr(x[i] + delta[i] == f[0, i])\n",
    "    ilp_model.addConstr(delta[i] <= input_diff[i])\n",
    "    ilp_model.addConstr(-delta[i] <= input_diff[i])\n",
    "\n",
    "# these constrains just ensure that the information is propagated with the given weights thru the network   \n",
    "for k in range(1,4):\n",
    "    for i in range(W[k-1].shape[1]):\n",
    "        ilp_model.addConstr(g.quicksum(W[k-1][j, i]*f[k-1, j] for j in range(W[k-1].shape[0])) + b[k-1][i] == y[k, i])\n",
    "        ilp_model.addConstr(f[k, i] == g.max_(y[k, i], 0))   # beware! this is not an ILP constraint. but can be translated into a one\n",
    "        \n",
    "x_input_flatten = x_test[test_idx, :].reshape(1, 28*28)\n",
    "for i in range(W[0].shape[0]):\n",
    "    ilp_model.addConstr(x[i] == x_input_flatten[0][i])\n",
    "\n",
    "    \n",
    "# force the incorrect classification by saing that the maximal-activation output cannot the one that is correct\n",
    "ilp_model.addConstr(max_activation == g.max_(f[3, k] for k in range(10)))\n",
    "ilp_model.addConstr(f[3, pred_class_by_dnn] <= 0.95*max_activation)\n",
    "\n",
    "\n",
    "ilp_model.setObjective(g.quicksum(input_diff[i] for i in range(W[0].shape[0])), sense=g.GRB.MINIMIZE)\n",
    "ilp_model.params.timelimit = 90\n",
    "ilp_model.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see, which adjustments of input are claimed to alter the prediction of the trained DNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_representation = np.array([delta[i].x for i in range(28*28)]).reshape(28, 28)\n",
    "plt.gray()\n",
    "plt.imshow(x_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite suprising result! Only a few pixels are changed and the network is fooled. Let us test it if it indeed the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_5615/3525659646.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mx_fooled_sample\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_test\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtest_idx\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mtest_idx\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_representation\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# add the generated noise to the test example\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_fooled_sample\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mprediction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprobability_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_fooled_sample\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "x_fooled_sample = np.add(x_test[test_idx:test_idx+1], x_representation)  # add the generated noise to the test example\n",
    "plt.gray()\n",
    "plt.imshow(x_fooled_sample[0])\n",
    "\n",
    "prediction = probability_model(x_fooled_sample)\n",
    "print('classified by the trained DNN as {} with probability p={}'.format(\n",
    "        max(range(10), key=lambda idx: prediction[0][idx]), max(prediction[0]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed it is true! The network was fooled, but it says its confidence of the output is not that high.\n",
    "\n",
    "## Fooling the network even more!\n",
    "\n",
    "So we can even more sophisticated attack - how about maximizing the probability of the wrong class given that only a few pixels deviate? In this case would be the network fooled such that it would think it is actually correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilp_model = g.Model()\n",
    "x = ilp_model.addVars(W[0].shape[0], vtype=g.GRB.CONTINUOUS, lb=0, ub=1)\n",
    "delta = ilp_model.addVars(W[0].shape[0], vtype=g.GRB.CONTINUOUS, lb=-1, ub=1)\n",
    "input_diff = ilp_model.addVars(W[0].shape[0], vtype=g.GRB.CONTINUOUS, lb=-1, ub=1)\n",
    "max_activation = ilp_model.addVar(vtype=g.GRB.CONTINUOUS, lb=0)\n",
    "f = {}\n",
    "y = {}\n",
    "for k in range(3):\n",
    "    for i in range(W[k].shape[0]):\n",
    "        f[k, i] = ilp_model.addVar(vtype=g.GRB.CONTINUOUS, lb=0)\n",
    "        y[k, i] = ilp_model.addVar(vtype=g.GRB.CONTINUOUS, lb=-float('inf'))\n",
    "for i in range(W[2].shape[1]):\n",
    "        f[3, i] = ilp_model.addVar(vtype=g.GRB.CONTINUOUS, lb=0)\n",
    "        y[3, i] = ilp_model.addVar(vtype=g.GRB.CONTINUOUS, lb=-float('inf'))\n",
    "for i in range(W[0].shape[0]):\n",
    "    ilp_model.addConstr(x[i] + delta[i] == f[0, i])\n",
    "    ilp_model.addConstr(delta[i] <= input_diff[i])\n",
    "    ilp_model.addConstr(-delta[i] <= input_diff[i])\n",
    "for k in range(1,4):\n",
    "    for i in range(W[k-1].shape[1]):\n",
    "        ilp_model.addConstr(g.quicksum(W[k-1][j, i]*f[k-1, j] for j in range(W[k-1].shape[0])) + b[k-1][i] == y[k, i])\n",
    "        ilp_model.addConstr(f[k, i] == g.max_(y[k, i], 0))\n",
    "        \n",
    "x_input_flatten = x_test[test_idx, :].reshape(1, 28*28)\n",
    "for i in range(W[0].shape[0]):\n",
    "    ilp_model.addConstr(x[i] == x_input_flatten[0][i])\n",
    "\n",
    "    \n",
    "ilp_model.addConstr(max_activation == g.max_(f[3, k] for k in range(10)))\n",
    "ilp_model.addConstr(f[3, pred_class_by_dnn] <= 0.95*max_activation)\n",
    "ilp_model.addConstr(g.quicksum(input_diff[i] for i in range(W[0].shape[0])) <= 6)   # at most 6 pixels (in the sum of intensities) are deviated\n",
    " \n",
    "\n",
    "ilp_model.setObjective(f[3, 7], sense=g.GRB.MAXIMIZE)\n",
    "ilp_model.params.timelimit = 120\n",
    "ilp_model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_representation = np.array([delta[i].x for i in range(28*28)]).reshape(28, 28)\n",
    "x_fooled_sample = np.add(x_test[test_idx:test_idx+1], x_representation)\n",
    "plt.gray()\n",
    "plt.imshow(x_fooled_sample[0])\n",
    "\n",
    "prediction = probability_model(x_fooled_sample)\n",
    "print('classified by trained DNN as {} with probability p={}'.format(\n",
    "        max(range(10), key=lambda idx: prediction[0][idx]), max(prediction[0]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite interesting as well - only these few pixels have fooled the trained DNN which thinks it gives good results with high confidence. This demonstrate that solution of many ML model might be very fragile, if they are not trained sofistically. Moreover, this lab assignment has demonstrated the power of ILP as a tool for the formal verification of complex systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More ideas for you to play with\n",
    "* How would you adjust the constraints to make the adversarial noise less visible to a naked eye?\n",
    "* We have generated the adversarial noise for a specific example in the test set. Try to apply it to other. Is the network still fooled? Can you generate a noise that would be applicable to more examples at once?\n",
    "* Can you find what is the most \"ideal\" representation of number 8 according to the trained network? Does the result suprises you? What does it say about the network? \n",
    "* Are so-called \"shallow\" models susceptible as well (e.g., decision trees/random forests - you might test with ILP as well)? \n",
    "* Which other \"systems\" could be analyzed with ILP?\n",
    "* How could you use ILP for training (finding good parameter values) robust networks? How large networks could you  realistically  train with the current technology?\n",
    "* What is the relation between the number of network parameters and robustness of the network. Does the drop-out improve the resistence to such attacks?\n",
    "* How would you validate the performance of a ML model better rather than the accuracy on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}